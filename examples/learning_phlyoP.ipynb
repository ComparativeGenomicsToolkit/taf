{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load necessary dependencies\n",
    "import os\n",
    "import taffy\n",
    "import taffy.lib\n",
    "import taffy.ml\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "## Decide what kind of architecture we're running on\n",
    "device = (  \n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+../tests/447-way/example_norm.sh:13> tree_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.nh \n",
      "+../tests/447-way/example_norm.sh:16> rerooted_tree_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.rerooted.nh \n",
      "+../tests/447-way/example_norm.sh:19> wig_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_hg38_chr22_22000000_22100000.phyloP.wig \n",
      "+../tests/447-way/example_norm.sh:22> alignment_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_hg38_chr22_22000000_22100000.anc.norm.taf.gz \n",
      "+../tests/447-way/example_norm.sh:25> rearranged_alignment_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.rearranged.taf.gz \n",
      "+../tests/447-way/example_norm.sh:28> final_alignment_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.final.taf.gz \n",
      "+../tests/447-way/example_norm.sh:31> sort_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt \n",
      "+../tests/447-way/example_norm.sh:34> filter_file=/Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-filter.txt \n",
      "+../tests/447-way/example_norm.sh:37> ref=hg38 \n",
      "+../tests/447-way/example_norm.sh:40> /Users/benedictpaten/CLionProjects/taffy/examples/..//scripts/manipulate_tree.py --reroot hg38 --out_file /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.rerooted.nh /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.nh\n",
      "${taffy_root}/scripts/manipulate_tree.py --reroot $ref --out_file  $tree_file  0.02s user 0.01s system 88% cpu 0.033 total\n",
      "+../tests/447-way/example_norm.sh:43> /Users/benedictpaten/CLionProjects/taffy/examples/..//scripts/tree_to_sort_file.py --traversal pre --reroot hg38 --out_file /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt --suffix_to_append_to_labels . /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.nh\n",
      "wooooo .\n",
      "${taffy_root}/scripts/tree_to_sort_file.py --traversal pre --reroot $ref    .  0.05s user 0.01s system 94% cpu 0.062 total\n",
      "+../tests/447-way/example_norm.sh:46> /Users/benedictpaten/CLionProjects/taffy/examples/..//scripts/tree_to_sort_file.py --out_file /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-filter.txt --no_leaf_nodes --suffix_to_append_to_labels . /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.nh\n",
      "wooooo .\n",
      "${taffy_root}/scripts/tree_to_sort_file.py --out_file $filter_file   .   0.03s user 0.01s system 93% cpu 0.034 total\n",
      "+../tests/447-way/example_norm.sh:49> /Users/benedictpaten/CLionProjects/taffy/examples/..//bin/taffy sort -i /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_hg38_chr22_22000000_22100000.anc.norm.taf.gz -n /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt -p /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt -d /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt --logLevel DEBUG\n",
      "+../tests/447-way/example_norm.sh:49> ../bin/taffy view -t /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1.rerooted.nh -b -c --runLengthEncodeBases\n",
      "Input file string : /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_hg38_chr22_22000000_22100000.anc.norm.taf.gz\n",
      "Output file string : (null)\n",
      "Sort file string : /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt\n",
      "Filter file string : (null)\n",
      "Pad file string : /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt\n",
      "Dup filter file string : /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-sort.txt\n",
      "Ignore first row : True\n",
      "Loaded the sort/filter file, got 892 rows\n",
      "Loaded the sort/filter file, got 892 rows\n",
      "Loaded the sort/filter file, got 892 rows\n",
      "taffy sort is done, 75 seconds have elapsed\n",
      "${taffy_root}/bin/taffy sort -i $alignment_file -n $sort_file -p $sort_file -  71.20s user 2.46s system 98% cpu 1:14.66 total\n",
      "../bin/taffy view -t $rerooted_tree_file -b -c --runLengthEncodeBases >   6.22s user 0.14s system 8% cpu 1:14.67 total\n",
      "+../tests/447-way/example_norm.sh:52> /Users/benedictpaten/CLionProjects/taffy/examples/..//bin/taffy annotate -i /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.rearranged.taf.gz -w /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_hg38_chr22_22000000_22100000.phyloP.wig --tagName phyloP --refPrefix hg38. -c\n",
      "${taffy_root}/bin/taffy annotate -i $rearranged_alignment_file -w $wig_file    5.28s user 0.03s system 99% cpu 5.325 total\n",
      "+../tests/447-way/example_norm.sh:55> /Users/benedictpaten/CLionProjects/taffy/examples/..//bin/taffy index -i /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.final.taf.gz\n",
      "${taffy_root}/bin/taffy index -i $final_alignment_file  0.62s user 0.01s system 99% cpu 0.623 total\n",
      "+../tests/447-way/example_norm.sh:59> echo 'Starting alignment'\n",
      "Starting alignment\n",
      "+../tests/447-way/example_norm.sh:60> /Users/benedictpaten/CLionProjects/taffy/examples/..//bin/taffy stats -i /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_hg38_chr22_22000000_22100000.anc.norm.taf.gz -a\n",
      "Total blocks:\t3166\n",
      "Total columns:\t215664\n",
      "Avg. columns/block:\t68.118759\n",
      "Total bases:\t67026589\n",
      "Total gaps:\t226206389\n",
      "Avg. column depth:\t1359.675171\n",
      "Avg. bases/column:\t310.791718\n",
      "Avg. gaps/column:\t1048.883423\n",
      "${taffy_root}/bin/taffy stats -i $alignment_file -a  9.08s user 0.08s system 99% cpu 9.207 total\n",
      "+../tests/447-way/example_norm.sh:62> echo 'Final alignment'\n",
      "Final alignment\n",
      "+../tests/447-way/example_norm.sh:63> /Users/benedictpaten/CLionProjects/taffy/examples/..//bin/taffy stats -i /Users/benedictpaten/CLionProjects/taffy/examples/..//tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.final.taf.gz -a\n",
      "Total blocks:\t3166\n",
      "Total columns:\t215664\n",
      "Avg. columns/block:\t68.118759\n",
      "Total bases:\t25013474\n",
      "Total gaps:\t167358814\n",
      "Avg. column depth:\t892.000000\n",
      "Avg. bases/column:\t115.983536\n",
      "Avg. gaps/column:\t776.016479\n",
      "${taffy_root}/bin/taffy stats -i $final_alignment_file -a  1.91s user 0.05s system 95% cpu 2.046 total\n"
     ]
    }
   ],
   "source": [
    "## Run shell script to normalize alignment and annotate with wig (comment this out if already run)\n",
    "!../tests/447-way/example_norm.sh `pwd`/../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alignment file to use: /Users/benedictpaten/CLionProjects/taffy/examples/../tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.final.taf.gz\n"
     ]
    }
   ],
   "source": [
    "## Annotated alignment file\n",
    "#alignment_file = os.path.join(os.getcwd(), \"../tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.rearranged.taf.gz\")\n",
    "alignment_file = os.path.join(os.getcwd(), \"../tests/447-way/447-mammalian-2022v1_chr22_22000000_22100000.final.taf.gz\")\n",
    "print(f\"The alignment file to use: {alignment_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a taf index\n",
    "\n",
    "# Write the index file\n",
    "index_file = alignment_file + \".tai\"\n",
    "taffy.lib.write_taf_index_file(taf_file=alignment_file, index_file=index_file)\n",
    "\n",
    "# Make the Taf Index object\n",
    "taf_index = taffy.lib.TafIndex(index_file, is_maf=False) #False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the following reference sequence intervals: [('hg38.chr22', 22000000, 100000)]\n"
     ]
    }
   ],
   "source": [
    "## Get the names of the sequences in the alignment\n",
    "\n",
    "# First make an alignment reader\n",
    "with taffy.lib.AlignmentReader(alignment_file) as ar:\n",
    "    # Now get the intervals\n",
    "    sequence_intervals = list(taffy.lib.get_reference_sequence_intervals(ar))\n",
    "\n",
    "print(f\"Got the following reference sequence intervals: {sequence_intervals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 3.7505669593811035 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "with taffy.lib.AlignmentReader(alignment_file, taf_index=taf_index, sequence_intervals=sequence_intervals) as ar:\n",
    "    for block in ar:\n",
    "        pass\n",
    "print(f\"It took {time.time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 4.391350030899048 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "with taffy.lib.AlignmentReader(alignment_file, taf_index=taf_index, sequence_intervals=sequence_intervals) as ar:\n",
    "    for column in taffy.lib.get_column_iterator(ar,\n",
    "                        include_sequence_names=False,\n",
    "                        include_non_ref_columns=False,\n",
    "                        include_column_tags=True):\n",
    "        pass\n",
    "print(f\"It took {time.time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 13.39326810836792 seconds, alignment depth: 5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "## Create a DataLoader for the alignment, print the first few entries and establish the alignment depth\n",
    "def get_alignment_iterator(batch_size=10, num_workers=1):\n",
    "    alignment_iterator = DataLoader(taffy.ml.TorchDatasetAlignmentIterator(alignment_file, \n",
    "                                                                            label_conversion_function=taffy.ml.get_phyloP_label,\n",
    "                                                                            taf_index_file=index_file, \n",
    "                                                                            is_maf=False,\n",
    "                                                                            sequence_intervals=sequence_intervals, \n",
    "                                                                            window_length=5,\n",
    "                                                                            step=1,\n",
    "                                                                            include_non_ref_columns=False,\n",
    "                                                                            include_sequence_names=False, \n",
    "                                                                            include_column_tags=True,\n",
    "                                                                            column_one_hot=True)\n",
    "                                    ,\n",
    "                                    batch_size=batch_size, num_workers=num_workers)\n",
    "    return alignment_iterator\n",
    "\n",
    "start = time.time()\n",
    "for column, labels in get_alignment_iterator():\n",
    "    alignment_depth = len(column[0])\n",
    "print(f\"It took {time.time()-start} seconds, alignment depth: {alignment_depth}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=5352, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Create a v. basic NN model with one hidden layer\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(alignment_depth * 6, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.flatten(X)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS device does not support linear for non-float inputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>7f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>5d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_alignment_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(X)\n\u001b[0;32m---> 17\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_relu_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS device does not support linear for non-float inputs"
     ]
    }
   ],
   "source": [
    "## Training functions\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error # nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "batch_size = 10\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    #size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y = y.float()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}]\")\n",
    "\n",
    "start = time.time()\n",
    "train(get_alignment_iterator(batch_size=batch_size, num_workers=1), model, loss_fn, optimizer)\n",
    "print(f\"It took {time.time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Examples: 100, Avg loss: 0.752171 \n",
      "\n",
      "Test Error: \n",
      " Examples: 200, Avg loss: 0.702954 \n",
      "\n",
      "Test Error: \n",
      " Examples: 300, Avg loss: 1.042747 \n",
      "\n",
      "Test Error: \n",
      " Examples: 400, Avg loss: 0.970533 \n",
      "\n",
      "Test Error: \n",
      " Examples: 500, Avg loss: 0.887299 \n",
      "\n",
      "Test Error: \n",
      " Examples: 600, Avg loss: 0.924819 \n",
      "\n",
      "Test Error: \n",
      " Examples: 700, Avg loss: 0.880741 \n",
      "\n",
      "Test Error: \n",
      " Examples: 800, Avg loss: 0.942342 \n",
      "\n",
      "Test Error: \n",
      " Examples: 900, Avg loss: 0.908017 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1000, Avg loss: 0.869284 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1100, Avg loss: 0.840072 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1200, Avg loss: 0.841252 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1300, Avg loss: 0.841908 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1400, Avg loss: 0.876804 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1500, Avg loss: 0.885639 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1600, Avg loss: 0.901369 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1700, Avg loss: 0.865082 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1800, Avg loss: 0.917225 \n",
      "\n",
      "Test Error: \n",
      " Examples: 1900, Avg loss: 0.906922 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2000, Avg loss: 1.148387 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2100, Avg loss: 1.400232 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2200, Avg loss: 2.631202 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2300, Avg loss: 3.957338 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2400, Avg loss: 3.919424 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2500, Avg loss: 4.049800 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2600, Avg loss: 3.906774 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2700, Avg loss: 4.033194 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2800, Avg loss: 3.941504 \n",
      "\n",
      "Test Error: \n",
      " Examples: 2900, Avg loss: 3.926370 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3000, Avg loss: 4.472844 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3100, Avg loss: 5.283722 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3200, Avg loss: 5.744477 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3300, Avg loss: 7.021147 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3400, Avg loss: 8.487399 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3500, Avg loss: 9.965269 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3600, Avg loss: 10.763929 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3700, Avg loss: 11.338408 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3800, Avg loss: 11.223779 \n",
      "\n",
      "Test Error: \n",
      " Examples: 3900, Avg loss: 12.003317 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4000, Avg loss: 12.222292 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4100, Avg loss: 13.098284 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4200, Avg loss: 13.150786 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4300, Avg loss: 13.487978 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4400, Avg loss: 13.874806 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4500, Avg loss: 13.804926 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4600, Avg loss: 13.632533 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4700, Avg loss: 14.303885 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4800, Avg loss: 14.864413 \n",
      "\n",
      "Test Error: \n",
      " Examples: 4900, Avg loss: 14.917860 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5000, Avg loss: 14.960422 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5100, Avg loss: 14.715881 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5200, Avg loss: 14.565087 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5300, Avg loss: 14.294280 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5400, Avg loss: 14.121350 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5500, Avg loss: 13.868518 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5600, Avg loss: 13.623939 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5700, Avg loss: 13.388352 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5800, Avg loss: 13.160887 \n",
      "\n",
      "Test Error: \n",
      " Examples: 5900, Avg loss: 13.210980 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6000, Avg loss: 13.615611 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6100, Avg loss: 13.775177 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6200, Avg loss: 13.849878 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6300, Avg loss: 13.705097 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6400, Avg loss: 13.578456 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6500, Avg loss: 13.642608 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6600, Avg loss: 13.504964 \n",
      "\n",
      "Test Error: \n",
      " Examples: 6700, Avg loss: 13.446826 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#test_loss /= num_batches\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#correct /= size\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Error: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Avg loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;241m/\u001b[39mexamples\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_alignment_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m test_loss, examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     10\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     11\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/CLionProjects/taffy/taffy_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Test functions\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    #size = len(dataloader.dataset)\n",
    "    #num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y = y.float()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            examples += 1\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            if examples % 100 == 0:\n",
    "                print(f\"Test Error: \\n Examples: {examples}, Avg loss: {test_loss/examples:>8f} \\n\")\n",
    "    #test_loss /= num_batches\n",
    "    #correct /= size\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss/examples:>8f} \\n\")\n",
    "\n",
    "test(get_alignment_iterator(batch_size=batch_size, num_workers=1), model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Putting it together\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
